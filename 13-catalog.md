
# Acceso a ADLS Gen2

## üóÇÔ∏èüî• CATALOG

### La Evoluci√≥n del Acceso Seguro a Datos en Databricks

---

### üö´üîë Credential Passthrough: **Descontinuado**

> ‚ö†Ô∏è **NOTA IMPORTANTE:**  
> Si antes hab√≠as trabajado con Databricks debes saber que a partir de **Databricks Runtime 15.0**, la opci√≥n de **credential passthrough** ha sido **eliminada** de la configuraci√≥n de cl√∫steres.  
> Ya no est√° disponible en la **UI de cl√∫steres**.

---

### ‚ùì ¬øQu√© era **Credential Passthrough**?

üßæ Era una funcionalidad que permit√≠a que los usuarios accedieran a **Azure Data Lake Storage (ADLS Gen2)** usando **su identidad personal** de Azure Active Directory (AAD).

|üßç‚Äç‚ôÇÔ∏è Usuario|üîê Acceso con su propia identidad|
|---|---|
|üë§ Juan|Accede con su usuario AAD|
|üë§ Mar√≠a|Accede con su usuario AAD|
|‚ùå Sin credenciales compartidas|‚úÖ M√°s seguro y auditado|

üìù **Ventajas que ofrec√≠a:**

- Evitaba el uso de **service principals** o claves compartidas

- Aumentaba la **seguridad basada en identidades**

- Permit√≠a una **auditor√≠a directa por usuario**


---

### üîÑ ¬øQu√© lo reemplaz√≥?

#### ‚ú®‚û°Ô∏è **Unity Catalog**: La Nueva Generaci√≥n de Gobernanza de Accesos

Databricks recomienda **migrar** a **Unity Catalog**, que provee:

|üõ†Ô∏è Caracter√≠stica|‚úÖ Unity Catalog|
|---|---|
|üîê Control de acceso granulado|‚úîÔ∏è Por cat√°logo, esquema, tabla y columna|
|üîé Auditor√≠a centralizada|‚úîÔ∏è Registro de accesos por usuario|
|üîó Integraci√≥n multi-workspace|‚úîÔ∏è Metastore compartido|
|üß≠ Gobernanza unificada|‚úîÔ∏è Modelo consistente de permisos|
|üßæ Linaje de datos|‚úîÔ∏è Rastreabilidad de or√≠genes y destinos|

---

#### üí° Comparaci√≥n

|üß± **Tecnolog√≠a**|üõë Credential Passthrough|‚úÖ Unity Catalog|
|---|---|---|
|üéØ Nivel de control|Usuario general (AAD)|Granular: cat√°logo ‚Üí columna|
|üåç Alcance|Por cl√∫ster|Multi-workspace|
|üìú Auditor√≠a|Limitada|Completa y centralizada|
|üîê Identidad|Individual del usuario|Gestionado v√≠a Unity + Identity Federation|
|üì¶ Soporte a futuro|‚ùå Descontinuado|‚úÖ Soportado y en evoluci√≥n|

---

üìåüìù Notas

> üåü **Credential passthrough fue √∫til‚Ä¶ pero estaba limitado.**  
> Ahora, Unity Catalog **no solo reemplaza**, sino que **mejora significativamente** el control de acceso con herramientas modernas, escalables y seguras.

> üîê **Unity Catalog** te permite aplicar **pol√≠ticas centralizadas**, con **auditor√≠a completa** y sin la necesidad de cl√∫steres especiales o configuraciones complejas.

---

### ‚úÖ Keys

üîª **Credential Passthrough:**  
Descontinuado desde DBR 15.0, limitado y sin soporte futuro.

üî∫ **Unity Catalog:**  
La soluci√≥n actual y recomendada:

- ‚úîÔ∏è M√°s seguro

- ‚úîÔ∏è M√°s escalable

- ‚úîÔ∏è Con mejor trazabilidad



---

## üöÄ‚ú® **Unity Catalog: La Nueva Era de la Gobernanza de Datos**

> üìö **Catalog** es la evoluci√≥n moderna del paradigma de gobernanza, metadatos y control de acceso a datos, superando tecnolog√≠as anteriores como _credential passthrough_ o el _Hive Metastore_ puro.

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img159.png)

### üß† ¬øQu√© es Unity Catalog?

üîê **Unity Catalog** es el componente de **gobernanza de datos** de **Databricks**. Centraliza en **un solo lugar** todo lo relacionado con:

|üîç **Funci√≥n**|‚úÖ **Descripci√≥n**|
|---|---|
|üîê Control de acceso|Gesti√≥n detallada de permisos de usuarios y grupos|
|üìú Auditor√≠a|Registro de actividad: qui√©n hizo qu√© y cu√°ndo|
|üîÅ Linaje de datos|Seguimiento del flujo de datos entre or√≠genes y destinos|
|üè∑Ô∏è Etiquetado|Clasificaci√≥n y organizaci√≥n de objetos de datos|
|üîé Descubrimiento|B√∫squeda y documentaci√≥n de activos de datos|
|üß≠ Metastore unificado|Compartido entre workspaces para consistencia y menor duplicaci√≥n|

---

### üß∞ Funcionalidades Principales

#### üéØ Permisos Finos por Nivel

> Control granular de acceso desde el **cat√°logo** hasta la **columna**.

üìÅ ‚û§ Cat√°logo  
üìÇ ‚û§ Esquema  
üìÑ ‚û§ Tabla  
üî§ ‚û§ Columna

üßë‚Äçüíº ‚ûï üë• Usuarios y Grupos

---

#### üîç Auditor√≠a y Linaje

üßæ **Logs detallados** ‚Üí Qui√©n accedi√≥, modific√≥ o consult√≥ cada recurso  
üîó **Linaje** ‚Üí Visualiza el recorrido completo de los datos  
üìà Desde la fuente ‚û°Ô∏è Transformaciones ‚û°Ô∏è Destino

üìù **Nota**

> La trazabilidad completa es esencial para el cumplimiento de normativas y la confianza en los datos.

---

#### üè∑Ô∏è Descubrimiento de Datos

üéØ Permite:

- üè∑Ô∏è Etiquetar objetos de datos (tablas, vistas, modelos, funciones)

- üìò Documentarlos con descripciones √∫tiles

- üîç Hacer b√∫squedas r√°pidas e inteligentes


üß© Ejemplo de objetos:

- üóÉÔ∏è Tablas

- üëÅÔ∏è‚Äçüó®Ô∏è Vistas

- ü§ñ Modelos

- ‚öôÔ∏è Funciones


üìù **Nota hermosa**

> "El descubrimiento efectivo acelera el an√°lisis, reduce duplicaciones y mejora la colaboraci√≥n."

---

### üè¢ Metastore Compartido

üö´ Antes:

- Cada _workspace_ ten√≠a su propio metastore

- üîÅ Metadatos duplicados

- ‚ö†Ô∏è Permisos inconsistentes


‚úÖ Ahora con **Unity Catalog**:

- üß† Un solo metastore centralizado

- üîÑ Compartido entre m√∫ltiples _workspaces_

- üß© Permisos consistentes y m√°s f√°ciles de gestionar


üìù **Nota**

> "Un metastore unificado reduce la complejidad y mejora la seguridad a escala."

---

### ‚úÖ ¬øEn qu√© se Diferencia de lo ‚ÄúAnterior‚Äù?

|‚öôÔ∏è **Tecnolog√≠a**|‚ùå **Antes (Hive/Legacy)**|‚úÖ **Ahora (Unity Catalog)**|
|---|---|---|
|üîë Control de acceso|Basado en archivos o ACLs|Fino, hasta nivel de columna|
|üîÑ Reutilizaci√≥n|Limitada entre workspaces|Metastore compartido|
|üìú Auditor√≠a|Poca o sin trazabilidad|Logs y linaje completo|
|üîç Descubrimiento|Manual y disperso|Integrado, etiquetado|
|üîê Seguridad a escala|Dif√≠cil de mantener|Consistente y centralizada|

---

#### ‚úÖUnity Catalog

- [‚úÖ] Centralizaci√≥n del gobierno de datos

- [‚úÖ] Control granular de permisos

- [‚úÖ] Auditor√≠a y trazabilidad total

- [‚úÖ] Metastore compartido entre workspaces

- [‚úÖ] Descubrimiento √°gil y documentado


---

### Keys

> üí° **Unity Catalog** no es solo una herramienta t√©cnica:  
> Es un **cambio de paradigma** en c√≥mo entendemos la **seguridad, descubrimiento y gobierno de datos** en el mundo moderno del _lakehouse_.

üéØ Ideal para organizaciones que buscan:

- Escalabilidad

- Seguridad de datos

- Cumplimiento normativo

- Democratizaci√≥n del acceso a datos


---

## ‚ö†Ô∏èüß© **Limitaciones y Cosas a Tener en Cuenta en Unity Catalog**

> üéØ Aunque **Unity Catalog** representa una mejora enorme en gobernanza de datos, su adopci√≥n y operaci√≥n traen ciertos **retos t√©cnicos y organizacionales** que debes conocer.

---

### üõ†Ô∏èüí° Requiere Configuraci√≥n Completa

üß± **No es plug-and-play**: Unity Catalog necesita una arquitectura bien configurada.

üîë **Elementos a configurar:**

- üë• Permisos y roles

- üîê Identidades federadas

- üåê _External Locations_

- üßæ _Storage Credentials_


üì¶ Todo esto **para que el acceso a los datos subyacentes sea controlado y funcional**.

üìù **Nota**

> "Habilitar Unity Catalog no garantiza acceso: sin configuraci√≥n adecuada del almacenamiento, los datos ser√°n inaccesibles."

---

### üßÆüì¶ Compatibilidad con Cl√∫steres y Runtimes

üîÑ **No todos los cl√∫steres soportan Unity Catalog** al 100%.

üìå **Requisitos m√≠nimos recomendados:**

- üöÄ Databricks Runtime **11.3+**

- ‚ùó Algunas funcionalidades requieren versiones **a√∫n m√°s recientes**


|üî¢ Versi√≥n de Runtime|üß∞ Compatibilidad con Unity Catalog|
|---|---|
|10.x o menor|‚ùå No compatible|
|11.3 LTS|‚úÖ Compatibilidad b√°sica|
|12.x en adelante|‚úÖ Mejores funcionalidades y soporte|

üìù **Nota**

> "Antes de migrar, revisa que los cl√∫steres usados por tu equipo soporten Unity Catalog."

---

### üì¶üîÑ Migraci√≥n de Datos y Permisos

üîÅ **Mover todo al nuevo cat√°logo no es autom√°tico** y puede implicar esfuerzo t√©cnico.

üëÄ Cosas a tener en cuenta:

- üìÇ Migrar tablas del antiguo **Hive metastore**

- üîÅ Reescribir rutas absolutas (ej. `dbfs:/`, `abfss:/`)

- ‚úèÔ∏è Actualizar scripts, notebooks, y jobs

- üßæ Reconfigurar permisos y accesos existentes


üìå **Resultado esperado:**  
üéØ Tener todos los objetos y accesos alineados con el nuevo modelo de gobernanza.

üìù **Nota**

> "Cada entorno es diferente: planifica la migraci√≥n como un proyecto, no como un cambio puntual."

---

### üö¶ Retos a Considerar

|‚ö†Ô∏è **Aspecto**|üß© **Detalle**|
|---|---|
|üîê Configuraci√≥n inicial|Necesaria para storage, permisos, identidades y external locations|
|üîÑ Compatibilidad de cl√∫steres|No todos los runtimes soportan UC; 11.3+ recomendado|
|üîß Migraci√≥n de metadatos|Requiere mover tablas, ajustar rutas y adaptar scripts|
|üë®‚Äçüíª Reentrenamiento del equipo|Cambia el modelo de permisos y uso de recursos|

---

### ‚úÖ Recomendaciones Finales

üîç **Antes de migrar:**

- Revisa tus versiones de runtime

- Eval√∫a tu infraestructura de almacenamiento

- Haz un inventario de tablas, scripts y permisos

- Prepara un plan de migraci√≥n por fases


---

## **Data Lake** a Databricks, estos son los pasos que debes seguir:

### üöÄ **¬øQu√© es Databricks en el Ecosistema Azure?**

üåê **Plataforma dentro de Azure, pero‚Ä¶ ¬øDe Terceros?**

Databricks es parte del ecosistema de **Azure**, pero no es un producto _nativo_ de Azure. Es un **servicio de terceros**, lo que implica ciertos detalles t√©cnicos importantes cuando trabajas con √©l.

---

ü§î **¬øQu√© significa esto?**

Al ser un servicio de terceros, **Databricks** no se conecta de forma **nativa** a los recursos de Azure de la misma manera que otras herramientas. Esto es crucial cuando quieres trabajar con tu **Data Lake**. üèûÔ∏è

---

‚ùå **¬øQu√© problemas genera esto?**

Cuando intentas conectar tu **Data Lake** `z2hdatalakesuffix`, en el que tienes tablas en **Parquet**, **Databricks** no se conecta directamente como **Data Factory** o **Synapse Analytics** lo har√≠an.

üîë **En resumen:**

- **Data Factory** y **Synapse Analytics** pueden conectarse sin configuraciones complicadas.
    
- **Databricks**, al ser un servicio de terceros, requiere pasos adicionales para la conexi√≥n. ‚öôÔ∏è
    

---

 üìä **Comparativa de Conexi√≥n a Data Lake**

|**Herramienta**|**Conexi√≥n Directa al Data Lake**|**Pasos Requeridos**|
|---|---|---|
|**Databricks**|‚ùå No directa|üîß Requiere configuraci√≥n adicional|
|**Azure Data Factory**|‚úÖ S√≠|‚ú® Simple, sin pasos extra|
|**Synapse Analytics**|‚úÖ S√≠|‚ú® Simple, sin pasos extra|

---

üìå **NOTA IMPORTANTE**

üîë **Recuerda** que la conexi√≥n de Databricks al Data Lake no es tan sencilla como otras herramientas nativas de Azure. Aunque no es imposible, **requiere m√°s pasos** y configuraci√≥n.

---

‚úîÔ∏è **¬øPor qu√© es √∫til saber esto?**

- üõ†Ô∏è **Evitar sorpresas** al trabajar con Databricks.
    
- üìà **Optimizar tiempos** al comprender c√≥mo conectar estos servicios correctamente.
    
- üîÑ **Mejorar la integraci√≥n** de Databricks con otros productos de Azure.

 Entoces como lo sulucionamos Access Connector for Azure Databricks

### üåê **Soluci√≥n: Access Connector for Azure Databricks**

üîë **¬øQu√© es el Access Connector?**

El **Access Connector** es una herramienta de **Azure Databricks** dise√±ada espec√≠ficamente para facilitar la conexi√≥n entre Databricks y los servicios de **Azure Storage** (como **Data Lake**). Usando este conector, podemos establecer una conexi√≥n segura y eficiente sin la necesidad de configurar pasos complejos manualmente. üõ†Ô∏è‚ú®

---

üìä **Proceso Simplificado con Access Connector**

|**Paso**|**Acci√≥n**|
|---|---|
|**1. Habilitar Access Connector**|Activar la herramienta en Azure Databricks.|
|**2. Configuraci√≥n de Permisos**|Asignar los permisos adecuados en Azure AD.|
|**3. Configurar Conexi√≥n**|Conectar Azure Databricks con el Data Lake usando el Access Connector.|
|**4. Verificaci√≥n**|Validar la conexi√≥n y accesibilidad de los datos.|

---

 üéØ **Ventajas del Access Connector**

- **üîí Seguridad Mejorada**: Al usar un **Access Connector**, aseguras una conexi√≥n m√°s segura entre **Databricks** y tu **Data Lake**, con autenticaci√≥n de Azure Active Directory.
    
- **‚ö° Integraci√≥n F√°cil**: Simplifica la conexi√≥n entre los servicios de Azure sin necesidad de pasos complicados.
    
- **üìà Escalabilidad**: Permite manejar grandes vol√∫menes de datos sin sacrificar rendimiento.
    

---

## üìù **Creaci√≥n de Access Connector for Azure Databricks en el grupo de recursos de Azure** 


---

### **Pasos para crear un Azure Data Factory en el Portal de Azure**

1. **Inicia sesi√≥n en el Portal de Azure**  
    üëâ [https://portal.azure.com](https://portal.azure.com/)
    
2. **Busca el servicio "Access Connector for Azure Databricks"**
    
    - En la barra superior de b√∫squeda escribe **Access Connector for Azure Databricks**.
        
    - Selecciona **Access Connector for Azure Databricks** en los resultados.
        
3. **Crear un nuevo Access Connector for Azure Databricks**
    
    - Haz clic en **+ Crear** o **+ Add**.
        

---

**Secci√≥n: Project details**

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img176.png)

Aqu√≠ defines a qu√© suscripci√≥n y grupo de recursos estar√° ligado el servicio.

- **Subscription**:  
    Seleccionas la suscripci√≥n de Azure donde se van a facturar y administrar los recursos. En tu caso est√° marcada como **Azure subscription 1**.
    
- **Resource group**:  
    El grupo de recursos donde quieres guardar este Data Factory. Ya seleccionaste `databricks_access_connector_suffix`.  
    (Los grupos de recursos sirven para organizar y administrar en conjunto todos los recursos relacionados con un proyecto: bases de datos, ADF, almacenamiento, etc.)
    


---

El siguiente paso es pasar directo a **Review + Create** y finalmente **Create** para desplegarlo.

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img177.png)

---

üëâ Con eso ya tienes tu **Access Connector for Azure Databricks** y listo para empezar a mover/transformar datos.

Al revisar el grupo de recursos de Azure correspondiente al proyecto, podr√°s confirmar que el nuevo servicio ha sido creado y ya se encuentra correctamente integrado

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img178.png)





## üåê **Accounts - Acceso a Azure Databricks**

### 1Ô∏è‚É£ **Ingresa a tu Cuenta de Azure Databricks**

üîë **Accede a [Azure Databricks - Login](https://accounts.azuredatabricks.net/login)**

* Inicia sesi√≥n con tu **correo** y **contrase√±a**.

---

### 2Ô∏è‚É£ **Accede al Portal de Administraci√≥n de Cuentas**

Despu√©s de iniciar sesi√≥n, ser√°s redirigido a la p√°gina de administraci√≥n de cuentas de **Azure Databricks**:

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img179.png)

---

### 3Ô∏è‚É£ **Verifica los Permisos del Usuario**

Aseg√∫rate de que tu usuario tenga permisos de **administrador** en **Azure y Databricks**.

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img181.png)

---

### 4Ô∏è‚É£ **Accede al *Unity Catalog***

Haz clic en el bot√≥n de **Catalog** para acceder al **Unity Catalog**:

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img182.png)

---

üîë **Repasemos ¬øQu√© es el *Unity Catalog*?**

El **Unity Catalog** es una herramienta esencial que permite gestionar, organizar y compartir datos en plataformas como **Databricks**.

**¬øPor qu√© es importante?**

* üìä Controla el acceso a los datos.
* üîí Gobierna los datos en toda tu infraestructura.

---

üìö **Componentes Clave del Unity Catalog**

El Unity Catalog est√° organizado en **3 niveles principales**:

1. **üóÇÔ∏è Metastore**: El contenedor principal que organiza todo.
2. **üìÅ Cat√°logos**: Unidades dentro del Metastore, que contienen esquemas.
3. **üìë Tablas/Vistas**: Los datos reales que se utilizan para an√°lisis.

---

üí° ***Metastore* - El Guardi√°n de los Datos**

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img183.png)


Un **metastore** es como una ‚Äúbase‚Äù que contiene cat√°logos, esquemas, tablas y vistas.

üîë **Dentro de un Metastore:**

* **üóÇÔ∏è** Se organizan **Cat√°logos**.
* **üìÅ** Cada cat√°logo puede tener **Esquemas** (bases de datos).
* **üìë** Los esquemas contienen **Tablas y Vistas**.

**üîç Notas:**

* **üåç Regi√≥n**: El **metastore** est√° ubicado en una regi√≥n espec√≠fica (por ejemplo, `eastus`).
* **üîÑ Actualizaci√≥n**: Los **metastore** se actualizan en tiempo real.

---

üìä **Estructura del *Catalog***

Cada **Catalog** contiene los datos organizados l√≥gicamente. Aqu√≠ tienes c√≥mo se ve:

| **Nombre**               | **Regi√≥n** | **Ruta**      | **Creado en** | **Actualizado en** |
| ------------------------ | ---------- | ------------- | ------------- | ------------------ |
| metastore\_azure\_eastus | eastus     | /path/to/data | 09/11/2025    | 09/11/2025         |

üîç **Notas Importantes**:

* **üñ•Ô∏è Nombre**: Cada **metastore** tiene un nombre √∫nico.
* **üìç Regi√≥n**: Indica la ubicaci√≥n geogr√°fica del **metastore** (por ejemplo, `eastus`).
* **üïí Fechas**: Las fechas de **creaci√≥n** y **actualizaci√≥n** son claves para saber cu√°ndo se actualiz√≥ por √∫ltima vez.

---

### üîß **¬øC√≥mo Funciona el *Unity Catalog*?**

1Ô∏è‚É£ **Crear un Metastore**

* **Ve a la interfaz de Unity Catalog**.
>	**üìùNOTA:** Antes de proceder con el siguiente paso, debes eliminar el Metastore que viene por defecto en este caso `metastore_azure_eastus` . 
* Solo debes seleccionarlo luego busca los tres puntos en la zona izquierda y clic en **Delete**. Sin este paso previo no podr√°s crear un nuevo Metastore. 

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img203.png)


* Ahora que haz eliminado el metastore anterior solo **Haz clic en "Crear Metastore"** para comenzar a organizar tus datos.
	![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img184.png)

---

üöÄ **Metastore en Databricks**

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img185.png)

Esta es la **pantalla principal** para crear un **Metastore** dentro del **Unity Catalog** de **Databricks**.

---

üß© **Secciones Clave del Formulario**

| üè∑Ô∏è Campo               | üìå Descripci√≥n                                                                                                          | üîí Obligatorio |
| ----------------------- | ----------------------------------------------------------------------------------------------------------------------- | -------------- |
| **Name**                | Nombre √∫nico para tu Metastore. ‚ö†Ô∏è Debe ser identificable y claro, como `metastore_proyecto_ventas`.                    | ‚úÖ S√≠           |
| **Region**              | Regi√≥n geogr√°fica donde se alojar√° el Metastore. Solo podr√°s  asignar un solo _workspaces_ de esta regi√≥n al Metastore. | ‚úÖ S√≠           |
| **ADLS Gen 2 path**     | Ruta de tu cuenta de almacenamiento ADLS Gen2 para guardar tablas gestionadas.                                          | ‚úÖ S√≠           |
| **Access Connector Id** | ID del Access Connector de Azure. Este recurso permite a Databricks acceder de forma segura al ADLS.                    | ‚úÖ S√≠           |

---

Ok, antes de continuar con con el completado del formulario debemos realizar un pasos extras. En primer lugar debemos ubicarnos en el storage de Azure en este caso en `z2hdatalakesuffix` y crear un nuevo contenedor al que llamaremos `metastorage` 

Para crear un Blob Container en Azure sigue estos pasos:

1. **Acceder a la opci√≥n de Blob Containers**:
    
    - En la barra lateral izquierda de tu cuenta de almacenamiento, selecciona **Storage browser**.
        
    - Dentro de esta secci√≥n, haz clic en **Blob containers** para visualizar los contenedores de blobs existentes.
        
2. **Crear un nuevo contenedor**:
    
    - Haz clic en el bot√≥n **+ Add container** que aparece en la parte superior de la pantalla.
        
3. **Configurar el contenedor**:
    
    - En el panel emergente que aparece a la derecha, se te solicitar√° que ingreses el **nombre** del contenedor. En este caso, se ha ingresado el nombre **metastorage**.
        
    - En la secci√≥n de **Anonymous access level**, selecciona la opci√≥n **Private (no anonymous access)** para garantizar que el contenedor no permita acceso an√≥nimo.
        
4. **Finalizar la creaci√≥n**:
    
    - Despu√©s de configurar el contenedor, haz clic en el bot√≥n **Create** para crear el Blob Container.
        

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img192.png)


Ahora debemos gestionar el control de acceso en un recurso de Azure:

1. **Acceder a "Access Control (IAM)"**:
    
    - En la barra lateral izquierda de tu cuenta de almacenamiento, selecciona **Access Control (IAM)**, que te permitir√° gestionar permisos y roles de acceso.
        
2. **Agregar una asignaci√≥n de rol**:
    
    - Dentro de la secci√≥n "Access Control (IAM)", haz clic en el bot√≥n **+ Add** y luego selecciona **Add role assignment**. Esto te permitir√° asignar un rol a un usuario, grupo, o identidad administrada para controlar el acceso a los recursos.

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img187.png)

En la secci√≥n de "Role" (Rol), se utiliza un cuadro de b√∫squeda para buscar el rol espec√≠fico: **"Storage Blob Data Contributor"**. Este rol permite la lectura, escritura y eliminaci√≥n de datos en los contenedores de Blob Storage en Azure.
    
1. **Descripci√≥n del rol**: Este rol permite acceso de **lectura, escritura y eliminaci√≥n** a los contenedores y datos de Azure Storage Blob.
    
2. **Categor√≠a y tipo de rol**:  Este rol pertenece a la categor√≠a **"Storage"** y es un **rol incorporado** (**BuiltInRole**).
    

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img188.png)



Ahora clic en **Next**

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img189.png)


        
3. En **Assign access to** (Asignar acceso a), selecciona **"Managed identity"**.
        
4. **Selecciona la identidad administrada de Databricks**:
    
    - En el cuadro **Select managed identities** (Seleccionar identidades administradas), busca la identidad administrada asociada con Databricks. Deber√°s encontrar algo como:
        
        - **Access Connector for Azure Databricks**
            
    - Esta identidad administrada se utiliza para permitir que el **Unity Catalog** de Databricks tenga acceso al almacenamiento de Azure.
        
5. **Selecciona los miembros**:
    
    - En la secci√≥n **Members** (Miembros), haz clic en **"Select members"** (Seleccionar miembros).
        
    - Busca la identidad de **Databricks** que hayas seleccionado previamente en este caso **databricks_access_connector_suffix**
    
	    ![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img190.png)
        
3. **Revisi√≥n y asignaci√≥n**:

	![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img191.png)
    
    - Una vez seleccionados los miembros, haz clic en **"Review + assign"** (Revisar y asignar).
        
    - Revisa los detalles y confirma que todo est√© correcto.
        
    - Finalmente, haz clic en **"Assign"** para completar el proceso de asignaci√≥n del rol.
        

**Resultado Final:** *Acceso de Unity Catalog de Databricks a Azure Blob Storage* üöÄ

üìù **Resumen**
Despu√©s de seguir estos pasos, el **Unity Catalog** de **Databricks** podr√° interactuar con el contenedor de **Azure Blob Storage** a trav√©s del **databricks_access_connector**. Esto permitir√° realizar operaciones de lectura, escritura y eliminaci√≥n, todo gestionado bajo el rol **"Storage Blob Data Contributor"**.

---

üõ†Ô∏è **Pasos que realizamos**

1Ô∏è‚É£  **Crear el Azure Blob Storage Container**

- En el portal de **Azure**, crea un contenedor en **Azure Blob Storage** donde se almacenar√°n los datos.
    

2Ô∏è‚É£ **Establecer un Rol en Azure**

- Aseg√∫rate de que el rol **"Storage Blob Data Contributor"** est√© asignado al servicio o a la entidad de seguridad que usar√° Databricks.
    

üîë **¬øPor qu√©?**  
Este rol garantiza que **Databricks** pueda realizar operaciones de:

- üìÑ **Lectura** (read)
    
- ‚úèÔ∏è **Escritura** (write)
    
- üóëÔ∏è **Eliminaci√≥n** (delete)
    

3Ô∏è‚É£ **Conecta el Contenedor de Azure con Databricks**

- Desde **databricks_access_connector**, configura la conexi√≥n entre **Azure Blob Storage** y el cat√°logo de datos de Databricks.
    

---

 üîÑ **Diagrama de flujo del proceso**

```plaintext
  [Azure Blob Storage]  --->  [databricks_access_connector]  --->  [Unity Catalog Databricks]
        |                                                             |
   üö™üîë (Rol Storage Blob Data Contributor)                       üìÅ (Operaciones de CRUD)
```

---

üö® **NOTA IMPORTANTE**

El acceso correcto al contenedor de **Azure Blob Storage** es **crucial** para que el **Unity Catalog** de **Databricks** pueda realizar las tareas necesarias sin interrupciones. Aseg√∫rate de seguir cada paso cuidadosamente y de que las credenciales y permisos est√©n correctamente configurados. üîê

---

üìã **Checklist** ‚úîÔ∏è

|**Paso**|**Acci√≥n**|
|---|---|
|üõ†Ô∏è **Paso 1**|Configurar Unity Catalog|
|üåê **Paso 2**|Crear contenedor en Azure Blob Storage|
|üîë **Paso 3**|Asignar rol "Storage Blob Data Contributor"|
|üîó **Paso 4**|Conectar Azure Blob Storage con Databricks|
|‚úÖ **Paso 5**|Verificar operaciones CRUD|

---

üõ†Ô∏è **Formulario Metastore en Databricks**

Para completar el proceso de **crear un metastore** en Databricks seg√∫n el formulario, sigue estos pasos:

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img193.png)

 1Ô∏è‚É£ **Especifica el Nombre del Metastore**

- En el campo **Name**, ingresa el nombre de tu metastore. Este ser√° el identificador de tu metastore en Databricks.  
    Ejemplo: **metastore_suffix**.
    

2Ô∏è‚É£ **Selecciona la Regi√≥n**

- En el campo **Region**, selecciona la regi√≥n donde deseas que se cree tu metastore.
    
- La regi√≥n elegida determinar√° en qu√© ubicaci√≥n f√≠sica se almacenar√°n los datos.
    
- En este caso, est√° seleccionado **eastus2**, pero puedes elegir otra regi√≥n que te convenga.
    

3Ô∏è‚É£ **Configura la Ruta de ADLS Gen 2 (Opcional)**

- En el campo **ADLS Gen 2 path**, puedes especificar una ruta en **Azure Data Lake Storage Gen 2** para almacenar los datos gestionados del metastore.
    
- Aseg√∫rate de que la ruta est√© correctamente estructurada:
    

```
abfss://metastore@z2hdatalakesuffix.dfs.core.windows.net/
```

4Ô∏è‚É£ **Proporciona el ID del Conector de Acceso**

- En el campo **Access Connector Id**, deber√°s ingresar el identificador del conector de acceso.

	En tu grupo de recursos `z2h-dataengineering-project-suffix` y selecciona `databricks_access_connector_suffix`
	
	![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img194.png)
	Luego en la pesta√±a **Overview** copia el **Resource ID**
	
	![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img195.png)

- Este es un v√≠nculo directo a tu recurso de acceso de Databricks, el cual deber√≠a tener el siguiente formato:
    

```
/subscriptions/{sub-id}/resourceGroups/{rg-name}/providers/Microsoft.Databricks/accessConnectors/{connector-id}
```

- Copy/Paste en el formulario.
![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img196.png)
    

 **Crear el Metastore**

- Una vez que hayas completado todos los campos, haz clic en el bot√≥n **Create** para crear tu metastore. Luego selecciona el Workspace que vamos a usar para este metastore en este caso `z2h-databricks-suffix` y luego clic en **Assign**

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img197.png)

---


Luego clic

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img198.png)

Luego ver√°s el siguiente mensaje de felicitaciones

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img199.png)