

# Compute

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img150.png)

---

## âš™ï¸ Â¿QuÃ© es la secciÃ³n **Compute**?

Es donde gestionas los **recursos de cÃ³mputo** que necesitas para ejecutar tus notebooks, tareas automatizadas (jobs), consultas SQL y modelos de machine learning. En pocas palabras, aquÃ­ creas y administras los clÃºsteres que te dan la potencia para trabajar con datos.

---

### ğŸ§© PestaÃ±as dentro de la secciÃ³n Compute:

1. **All-purpose compute**
    
    - AquÃ­ creas **clÃºsteres interactivos**, ideales para notebooks colaborativos y exploraciÃ³n de datos en tiempo real.
        
    - Se pueden compartir entre usuarios y se mantienen activos mientras los necesitas.
        
2. **Job compute**
    
    - ClÃºsteres dedicados a la ejecuciÃ³n de **jobs automÃ¡ticos o programados**.
        
    - Son efÃ­meros: se inician cuando comienza un trabajo y se apagan al terminar, optimizando costos.
        
3. **SQL Warehouses**
    
    - Infraestructura especializada para ejecutar **consultas SQL** con alto rendimiento.
        
    - Son ideales para dashboards o herramientas de BI conectadas a Databricks.
        
4. **Vector Search**
    
    - Permite crear Ã­ndices para hacer **bÃºsquedas vectoriales** (por ejemplo, para IA generativa o motores de recomendaciÃ³n).
        
    - Aparece si tienes activada esta funcionalidad (en vista previa o ediciÃ³n especÃ­fica).
        
5. **Pools**
    
    - Agrupan instancias previamente activadas para reducir el tiempo de inicio de clÃºsteres.
        
    - Ãštil cuando necesitas ejecutar jobs frecuentemente y no quieres esperar a que un clÃºster arranque desde cero.
        
6. **Policies**
    
    - AquÃ­ defines polÃ­ticas para controlar cÃ³mo se crean los clÃºsteres.
        
    - Puedes limitar el tipo de mÃ¡quinas, tamaÃ±o, duraciÃ³n, etc., segÃºn necesidades o presupuestos del equipo.
        
7. **Apps**
    
    - Muestra aplicaciones o integraciones desplegadas dentro del entorno de Databricks.
        
    - No siempre estÃ¡ activo, depende de tu configuraciÃ³n.
        
8. **Lakebase Postgres**
    
    - Una nueva integraciÃ³n con PostgreSQL para facilitar consultas y sincronizaciÃ³n de datos.
        
    - AÃºn puede estar en versiÃ³n preview o restringida a ciertas ediciones.
        

---

### ğŸ› ï¸ Otras funcionalidades destacadas en la pantalla:

- **Create with Personal Compute**: Te permite iniciar un clÃºster personal rÃ¡pidamente con una configuraciÃ³n predeterminada.
    
- **Create compute**: Abre el asistente para configurar tu propio clÃºster (tipo de instancia, nÃºmero de nodos, polÃ­ticas, etc.).
    
- **Filtros y columnas**: Puedes buscar, ordenar o filtrar clÃºsteres por nombre, creador, polÃ­tica, uso de recursos, etc.
    

---

### âœ… KEYS:

La secciÃ³n **Compute** es el corazÃ³n operativo de Databricks. AquÃ­ defines con cuÃ¡nta potencia vas a trabajar, cÃ³mo se usa esa potencia (interactiva o automÃ¡tica), y cuÃ¡nto control tienes sobre su comportamiento. Organizar bien esta parte es clave para balancear rendimiento y costos.



---

## **Create Compute**

Ahora nos posicionamos en la pestaÃ±a **All-purpose compute** dentro de la secciÃ³n **Compute** de Databricks. AquÃ­ es donde puedes crear clÃºsteres interactivos para trabajar con notebooks, probar cÃ³digo, explorar datos y colaborar con otros usuarios.

---

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img151.png)

### ğŸŸ¨ MenÃº desplegable de polÃ­ticas de cÃ³mputo

ğŸ“**Haz clic:** Parte superior derecha, junto al botÃ³n azul "Create compute"

Este menÃº desplegable permite seleccionar **la polÃ­tica con la cual crear tu recurso de cÃ³mputo**, y es clave para definir cÃ³mo se comportarÃ¡ ese clÃºster. Las opciones que se muestran son:

- **Create with Personal Compute**  
    â†’ Crea un clÃºster solo para ti. Nadie mÃ¡s podrÃ¡ conectarse ni compartirlo. Ideal para trabajo individual, pruebas o desarrollo personal.
    
- **Create with Power User Compute**  
    â†’ Pensado para usuarios avanzados que requieren mÃ¡s control sobre la configuraciÃ³n. Suele permitir elegir mÃ¡s tipos de instancias o configuraciones personalizadas.
    
- **Create with Shared Compute**  
    â†’ Crea un clÃºster que puede ser compartido entre varios usuarios. Ãštil para equipos que colaboran en los mismos notebooks o procesos.
    

> ğŸ” Estas "polÃ­ticas" no solo definen permisos, sino tambiÃ©n lÃ­mites de recursos, tipos de instancias permitidas, tiempo de vida del clÃºster, etc.

---

### ğŸŸ¨ BotÃ³n **Create compute**

ğŸ“**UbicaciÃ³n:** Parte central inferior

Este botÃ³n es el **acceso directo para iniciar un nuevo clÃºster** desde cero. Al hacer clic, se abre un asistente donde puedes definir:

- Nombre del clÃºster
    
- Tipo de mÃ¡quina y nÃºmero de nodos
    
- VersiÃ³n del entorno (Databricks Runtime)
    
- PolÃ­ticas aplicadas
    
- Configuraciones avanzadas como autoscaling, acceso a librerÃ­as, etc.
    

> ğŸ’¡ Este botÃ³n aparece cuando no tienes ningÃºn clÃºster activo, como en la imagen que indica â€œNo computeâ€.

---

ğŸ”š En resumen:

Puedes crear tu entorno de ejecuciÃ³n en Databricks usando distintas polÃ­ticas de cÃ³mputo. Puedes elegir si el clÃºster serÃ¡ personal, compartido o avanzado

Ahora haz clic en **â€œCreate computeâ€** para empezar a trabajar. Este paso es esencial, ya que sin un clÃºster activo no puedes ejecutar notebooks ni consultas.

---

## Formulario para **crear un nuevo clÃºster**

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img152.png)

Perfecto. Ahora que estas en el formulario para **crear un nuevo clÃºster** en Databricks y tu objetivo es crear **un clÃºster personal, pequeÃ±o y de prueba**, lo cual es ideal para desarrollo ligero o validaciÃ³n de cÃ³digo. Vamos a revisar **cada secciÃ³n paso a paso**, explicando quÃ© significa y cÃ³mo configurarlo eficientemente para nuestro proyecto.

---

### ğŸ§¾ **1. General**

|Campo|DescripciÃ³n|RecomendaciÃ³n para pruebas|
|---|---|---|
|**Compute name**|Nombre del clÃºster. Databricks genera uno automÃ¡tico con fecha/hora.|Puedes dejar el nombre por defecto o poner algo como `"test-cluster"` para identificarlo fÃ¡cilmente.|
|**Policy**|Determina las reglas aplicadas al clÃºster (recursos mÃ¡ximos, configuraciÃ³n permitida, etc.).|Si ves â€œUnrestrictedâ€, significa que no hay restricciones. Ideal para pruebas rÃ¡pidas.|

---

### âš™ï¸ **2. Performance**

AquÃ­ defines la potencia y capacidades del clÃºster:

#### âœ… Machine learning (opcional)

- **Si se activa**, el clÃºster incluye bibliotecas de ML preinstaladas (MLflow, scikit-learn, etc.).
    
- **Para pruebas simples**, puedes **dejarlo desactivado**, a menos que estÃ©s haciendo algo de ML.
    

#### âš¡ Databricks runtime

- Es la versiÃ³n del entorno base (Scala + Spark + librerÃ­as).
    
- En la imagen estÃ¡ seleccionado: **`16.4 LTS`**, lo cual es una versiÃ³n estable y con soporte extendido.
    
- **EstÃ¡ bien dejarlo asÃ­.**
    

#### ğŸ§  Photon acceleration (opcional)

- Acelera el procesamiento en ciertas cargas de trabajo SQL y DataFrame.
    
- **Puedes dejarlo activado**, no genera sobrecostos si no se usa.
    

#### ğŸ–¥ï¸ Worker type

- El tipo de mÃ¡quina virtual que se usarÃ¡ como **nodo trabajador** del clÃºster.
    
- Por default se usa: **`Standard_D4ds_v5` (16 GB RAM, 4 cores)**
    
- **Para reducir costos**, puedes cambiar a algo mÃ¡s pequeÃ±o como `Standard_D2ds_v5` (8 GB, 2 cores), si estÃ¡ disponible.
    

#### ğŸ”„ Autoscaling (habilitado)

- Escala automÃ¡ticamente el nÃºmero de nodos segÃºn la carga.
    
- **Ideal para pruebas**, ya que puedes empezar con 2 nodos y crecer hasta 8 solo si es necesario.
    

#### â±ï¸ Terminate after X minutes of inactivity

- Si no se usa el clÃºster por el tiempo definido, se apaga automÃ¡ticamente para **evitar costos innecesarios**.
    
- En la imagen estÃ¡ configurado en **120 minutos**, lo cual estÃ¡ bien para pruebas. Puedes bajarlo a 30 si quieres mayor control de costos.
    

#### ğŸ§¬ Advanced performance (plegable)

- Configuraciones mÃ¡s tÃ©cnicas como tipo de disco, GPU, etc.
    
- Puedes **ignorarlo** para este caso de prueba.
    

---

### ğŸ·ï¸ **3. Tags**

- Puedes asignar etiquetas clave/valor para organizar y rastrear costos o recursos.
    
- **No es obligatorio**. Puedes dejarlo vacÃ­o.
    

---

### ğŸ“¦ **4. Advanced** (plegable)

- AquÃ­ puedes configurar librerÃ­as, scripts de inicio, variables de entorno, etc.
    
- **No es necesario tocarlo para un clÃºster de pruebas.**
    

---

### ğŸ§¾ **5. Panel derecho â€“ Resumen**

|SecciÃ³n|QuÃ© muestra|
|---|---|
|**Summary**|Rango estimado de recursos segÃºn la configuraciÃ³n (memoria y nÃºcleos).|
|**Data access**|Muestra que el clÃºster podrÃ¡ acceder a los datos gestionados por **Unity Catalog**.|
|**Price**|EstimaciÃ³n del costo por hora en DBUs (Databricks Units). Esto varÃ­a segÃºn tu contrato cloud.|

TambiÃ©n puedes alternar entre **UI y JSON**, para ver la configuraciÃ³n en formato de cÃ³digo.

---

## **clÃºster personal**


![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img153.png)

Ahora crearemos un **clÃºster personal, de bajo costo, en modo single-node**, con una versiÃ³n estable de Spark y aceleraciÃ³n activada. AdemÃ¡s, estableceremos un apagado automÃ¡tico muy corto (10 min), lo que **minimiza riesgos de cobros innecesarios**. Es una configuraciÃ³n excelente para pruebas pequeÃ±as o notebooks exploratorios.

## **Advanced**

![](../../../../static/img/0%20-%20Programs/1%20-%20DataEngineering/6%20-%20Azure/img154.png)

En esta secciÃ³n **Advanced** es para la configuraciÃ³n de un clÃºster en Databricks, donde puedes definir algunos parÃ¡metros adicionales para personalizar el comportamiento del clÃºster. AquÃ­ te explico cada parte:

---

#### 1. **Access mode**

- **Auto**: El clÃºster se gestiona automÃ¡ticamente, lo que significa que Databricks decide el nivel de acceso a los recursos segÃºn sea necesario (normalmente la opciÃ³n predeterminada).
    
- **Manual**: AquÃ­ puedes gestionar manualmente los recursos y configuraciones de acceso. Esto te da mÃ¡s control, pero es mÃ¡s adecuado para configuraciones avanzadas o especÃ­ficas que no requieren la gestiÃ³n automÃ¡tica.
    

> **RecomendaciÃ³n**: En un entorno de prueba y sin configuraciones especÃ­ficas de seguridad, **deja el modo en "Auto"**. Esto es ideal para no complicarte con configuraciones adicionales que no son necesarias en este caso.

#### 2. **Logging**

- Esta opciÃ³n permite configurar el registro de logs para el clÃºster.
    
- **Logging** permite rastrear eventos, errores y actividades dentro del clÃºster, y es Ãºtil si deseas realizar auditorÃ­as o monitorizar el uso.
    

> **RecomendaciÃ³n**: Para pruebas bÃ¡sicas, **no necesitas cambiar esta opciÃ³n**, ya que no se requiere un registro detallado a menos que estÃ©s buscando depurar problemas complejos.

#### 3. **Init scripts**

- Los **init scripts** son secuencias de comandos que se ejecutan cuando el clÃºster se inicia, lo que te permite instalar librerÃ­as adicionales, configurar variables de entorno o realizar otras personalizaciones.
    
- Esta opciÃ³n te deja aÃ±adir scripts personalizados para modificar tu entorno antes de usarlo.
    

> **RecomendaciÃ³n**: Para pruebas sencillas, **no es necesario utilizar init scripts** a menos que estÃ©s buscando preconfigurar algo especÃ­fico para tu proyecto.

#### 4. **JDBC/ODBC**

- Estas configuraciones permiten establecer conexiones mediante los protocolos JDBC o ODBC a otras bases de datos o sistemas externos.
    
- Se usa cuando deseas conectar Databricks con bases de datos externas como MySQL, PostgreSQL, o incluso otros entornos en la nube.
    

> **RecomendaciÃ³n**: **No es necesario para un clÃºster de prueba**, a menos que vayas a conectar con una base de datos externa de forma constante.

---

### ğŸ” **Acceso y Seguridad**

En la parte inferior, ves un candado al lado de **Standard** en "Access mode". Esto indica que el acceso a esta configuraciÃ³n estÃ¡ restringido por polÃ­ticas o permisos en tu cuenta. No podrÃ¡s cambiarlo si no tienes los privilegios necesarios.

---

âœ… **KEYS**

La secciÃ³n **Advanced** te permite personalizar detalles adicionales del clÃºster, pero para pruebas sencillas, **puedes dejar estas opciones tal como estÃ¡n**. Configura el acceso en modo **Auto**, no es necesario habilitar logging o scripts de inicializaciÃ³n, y no necesitas conectar a bases de datos externas.

## âœ… Â¿QuÃ© hacer ahora?

Una vez revisado todo:

- Haz clic en **Create** para iniciar el clÃºster.
    
- Espera unos minutos hasta que cambie a estado `Running`.
    
- Â¡Listo! Ya puedes abrir un notebook y empezar a probar cÃ³digo.
    

---

